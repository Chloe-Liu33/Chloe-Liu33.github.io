
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="keywords" content="Hongsheng Li, Hongsheng Li, EE, CUHK" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="rui.ico">
<title>Hongsheng Li at CUHK</title>
</head>
<body>
<div id="layout-content">
<p>

<script type="text/javascript">
<!--
// Toggle Display of BibTeX
function toggleBibtex(articleid) {
  var bib = document.getElementById(articleid);
  // Toggle 
    if(bib.style.display == "none") {
      bib.style.display = "";
    }
    else {
      bib.style.display = "none";
    }
}
-->
</script>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-40926388-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

</p>

<p>
</p>
<table class="imgtable"><tr><td>
<img src="figures/hongsheng_li.jpg" alt="alt text" width="180px" height="HEIGHTpx" /> &nbsp;</td>
<td align="left">

<div id="toptitle"> 
  <h1>
  <a href="http://www.ee.cuhk.edu.hk/~hsli/">Hongsheng Li</a> &nbsp; <font face="KaiTi">李鴻升</font>
  </h1>
</div>

<p>
Assistant Professor <br />

<br />


<a href="http://www.ee.cuhk.edu.hk">Department of Electronic Engineering</a> <br />

Co-affiliated to <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory</a> <br />

The Chinese University of Hong Kong<br />


<br />

Email: <a href="mailto:hsli@ee.cuhk.edu.hk">hsli@ee.cuhk.edu.hk</a><br />
Office: SHB 428, CUHK, 
Hong Kong S.A.R., China
</p>
</td></tr></table>

&nbsp;&nbsp;[<a href="http://scholar.google.com/citations?user=BN2Ze-QAAAAJ">Google Scholar</a>] 

</ul>

<h2>
  News 
</h2>
<ul>

  

  <li>
  <p> 1 paper accepted to CoRL 2020
  </p>
  </li>

  
  <li>
  <p> My supervised student, <a href="https://sshaoshuai.github.io/">Mr. Shaoshuai Shi</a>, has been awarded <a href="https://ai.googleblog.com/2020/10/announcing-2020-google-phd-fellows.html">2020 Google PhD Fellowship</a> (the only awardee in Hong Kong S.A.R.). Congrats to Shaoshuai!
  </p>
  </li>

  <li>
  <p> We have released <a href="https://github.com/open-mmlab/OpenPCDet">OpenPCDet</a> and <a href="https://github.com/open-mmlab/https://github.com/open-mmlab/OpenUnReID">OpenUnReID</a> codebase, the highly-optimized modular toolboxes for LiDAR-based 3D object detection and unsupervised person re-identification.
  </p>
  </li>

</ul>

<h2>
  Education 
</h2>
<ul>
  <li>
  <p>Ph. D., 2008 - 2012, <a href="http://www.cse.lehigh.edu/">Computer Science</a>, <a href="http://www.lehigh.edu/">Lehigh University</a>
  </p>

  <li>
  <p>M. Eng. student, 2006 - 2007, <a href="http://www.automation.sjtu.edu.cn/">Pattern Recognition and Intelligent System</a>, <a href="http://www.sjtu.edu.cn/">Shanghai Jiao Tong Universtiy</a>
  </p>

  <li>
  <p>B. Eng., 2002 - 2006, Automation, <a href="http://www.ecust.edu.cn/">East China University of Science and Technology</a>
  </p>
</li>
</ul>

<h2>
  Work Experience 
</h2>
<ul>

<li>
  <p>Assistant Professor, Jul. 2018 - Present, <a href="http://www.ee.cuhk.edu.hk/">Department of Electronic Enigneering</a>, <a href="http://www.cuhk.edu.hk">The Chinese University of Hong Kong</a>
  </p>
</li>

<li>
  <p>Huashan Scholar Chair Professor, Apr. 2020 - Present, <a href="https://cs.xidian.edu.cn/">School of Computer Science and Technology</a>, <a href="https://www.xidian.edu.cn/index.htm">Xidian University</a>
  </p>
</li>

<!--<li>
  <p>Director, May. 2020 - Present, <a> Centre for Perceptual and Interactive Intelligence (CPII) Limited (A research hub supported by Hong Kong SAR Government and CUHK)</a>
  </p>
</li>
-->

<li>
  <p>Research Assistant Professor, Aug. 2015 - Jun. 2018, <a href="http://www.ee.cuhk.edu.hk/">Department of Electronic Enigneering</a>, <a href="http://www.cuhk.edu.hk">The Chinese University of Hong Kong</a>
  </p>
</li>


</ul>

<h2>
  Awards & Competitions
</h2>
<ul>


<li>
  <p>Team Co-leader, Winner of <a href="http://image-net.org/challenges/LSVRC/2015/results">ImageNet Video Object Detection Challenge with provided data, 2015</a>
  </p>
</li>
 
</ul>


<h2>Publications</h2> 
<ul>


  <h3>Selected Preprints</h3>

  <li>
  <a href="https://arxiv.org/abs/2106.01401">Container: Context Aggregation Network,</a> <br />
  P. Gao, J. Lu, <b>H. Li</b>, R. Mottaghi, A. Kembhavi. <br /> arXiv:2106.01401, Technical Report, 2021. <br />
  </li>
  <br />  

  

 
 

 
  <li>
  <a href="https://arxiv.org/abs/2103.05346">ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection,</a> <br />
  J. Yang, S. Shi, <b>H. Li</b>, X. Qi. <br /> 
  <i>IEEE Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2021. <br />
  </li>
  <br />

  <li>
  <a href="https://arxiv.org/abs/2102.04010">Learning N:M Fine-grained Structured Sparse Neural Networks From Scratch,</a> <br />
  A. Zhou, Y. Ma, J. Zhu, J. Liu, Z. Zhang, K. Yuan, W. Sun, <b>H. Li</b>. <br /> 
  <i>International Conference on Learning Representations</i> (<b>ICLR</b>), 2021. <br />
  </li>
  <br />

  <li>
  <a href="https://arxiv.org/abs/1812.01243">Efficient Attention: Attention with Linear Complexities,</a> <br />
  Z. Zhao, M. Zhang, H. Zhao, S. Yi, <b>H. Li</b>. <br /> 
  <i>Winter Conference on Applications of Computer Vision</i> (<b>WACV</b>), 2021. <br />
  </li>
  <br />

  <li>
  <a href="https://www.sciencedirect.com/science/article/pii/S136184152030195X">FocusNetv2: Imbalanced Large and Small Organ Segmentation with Adversarial Shape Constraint for Head and Neck CT Images,</a> <br />
  Y. Gao, R. Huang, Y. Yang, J. Zhang, K. Shao, C. Tao, Y. Chen, D. N. Metaxas, <b>H. Li*</b>, M. Chen* (*Co-corresponding authors). <br /> 
  <i>Medical Image Analysis</i> (<b>MedIA</b>), Accepted. <br />
  </li>
  <br />

  <h3>


  


 


  
  <li>
  <a href="https://arxiv.org/abs/1909.05506">CAMP: Cross-modal Adaptive Message Passing for Text-image Retrieval,</a> <br />
  Z. Wang, X. Liu,  <b>H. Li</b>, L. Sheng, J. Yan, X. Wang, J. Shao <br />
  <i>International Conference on Computer Vision</i> (<b>ICCV</b>), 2019. <br />
  </li>
  <br />  

  <li>
  <a href="https://arxiv.org/abs/1905.00292">AdaCos: Adaptively Scaling Cosine Logit for Learning Deep Face Representation,</a>  <br />
  X. Zhang, R. Zhao, Y. Qiao, X. Wang, <b>H. Li</b> <br />
  <i>IEEE Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2019 (<b>oral presentation</b>). <br />
  </li>
  <br />


 

  


  
</ul>

<h2>
 Old Code
</h2>
<ul>
  <li>
  <p><a href="https://www.dropbox.com/s/wga70zfu53xs1y4/caffe.zip?dl=0">FastFPBP</a>: code of fast CNN for pixelwise classification (arXiv:1412.4526) based on Caffe's original implementation.
  </p>
  </li>

  <li>
  <p><a href="https://www.dropbox.com/s/3akau3qifpaai8x/PAMI14_ICCV11_matching_demo.zip?dl=0">PAMI14_ICCV11_matching_demo.zip</a>: demo code for our T-PAMI'14 and ICCV'11 papers.
  </p>
  </li>

  <li>
  <p><a href="https://www.dropbox.com/s/rp83scp7xvfd5dz/PAMI13_CVPR10_Matching_v0.1.zip?dl=0">PAMI13_CVPR10_Matching_v0.1.zip</a>: demo code for our T-PAMI'13 and CVPR'10 papers.
  </p>
  </li>
</ul>

<div id="footer">
<div id="footer-text">
  Last updated on Aug. 11th, 2021.
</div>
</div>

</body>
</html>
